{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: torch in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: transformers in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: datasets in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: evaluate in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.11)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install numpy torch torchvision torchaudio transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments\n",
    "from transformers import Trainer, DataCollatorForTokenClassification\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"O\",\n",
    "    \"LDEMO\",\n",
    "    \"LB\",\n",
    "    \"VBA\",\n",
    "    \"LGROUND\",\n",
    "    \"LBALL\",\n",
    "    \"LSP\",\n",
    "    \"VSPEED\",\n",
    "    \"LD\",\n",
    "    \"VDIR\",\n",
    "    \"LBRAKE\",\n",
    "    \"LSTE\",\n",
    "    \"VSTEER\",\n",
    "    \"LTHROT\",\n",
    "    \"VTHROTTLE\",\n",
    "    \"LBOOST\",\n",
    "    \"LPOS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label = {\n",
    "#     0: \"O\",\n",
    "#     1: \"L-DEMO\",\n",
    "#     2: \"L-BA\",\n",
    "#     3: \"V-BA\",\n",
    "#     4: \"L-GROUND\",\n",
    "#     5: \"L-BALL\",\n",
    "#     6: \"L-SPEED\",\n",
    "#     7: \"V-SPEED\",\n",
    "#     8: \"L-DIR\",\n",
    "#     9: \"V-DIR\",\n",
    "#     10: \"L-BRAKE\",\n",
    "#     11: \"L-STEER\",\n",
    "#     12: \"V-STEER\",\n",
    "#     13: \"L-THROTTLE\",\n",
    "#     14: \"V-THROTTLE\",\n",
    "#     15: \"L-BOOST\",\n",
    "#     16: \"L-POS\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2id = {\n",
    "#     \"O\": 0,\n",
    "#     \"L-DEMO\": 1,\n",
    "#     \"L-BA\": 2,\n",
    "#     \"V-BA\": 3,\n",
    "#     \"L-GROUND\": 4,\n",
    "#     \"L-BALL\": 5,\n",
    "#     \"L-SPEED\": 6,\n",
    "#     \"V-SPEED\": 7,\n",
    "#     \"L-DIR\": 8,\n",
    "#     \"V-DIR\": 9,\n",
    "#     \"L-BRAKE\": 10,\n",
    "#     \"L-STEER\": 11,\n",
    "#     \"V-STEER\": 12,\n",
    "#     \"L-THROTTLE\": 13,\n",
    "#     \"V-THROTTLE\": 14,\n",
    "#     \"L-BOOST\": 15,\n",
    "#     \"L-POS\": 16\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cw1521/nl-st\")\n",
    "dataset[\"train\"] = dataset[\"train\"].shard(10, 0)\n",
    "dataset[\"validation\"] = dataset[\"validation\"].shard(10, 0)\n",
    "dataset[\"test\"] = dataset[\"test\"].shard(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ner_ids', 'ner_sentence', 'ner_tags', 'sentence', 'state', 'tokens'],\n",
       "        num_rows: 86533\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ner_ids', 'ner_sentence', 'ner_tags', 'sentence', 'state', 'tokens'],\n",
       "        num_rows: 24724\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ner_ids', 'ner_sentence', 'ner_tags', 'sentence', 'state', 'tokens'],\n",
       "        num_rows: 12362\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'heading',\n",
       " 'east',\n",
       " '.',\n",
       " 'I',\n",
       " 'cu',\n",
       " '##rre',\n",
       " '##n',\n",
       " '##ly',\n",
       " 'have',\n",
       " '34',\n",
       " 'percent',\n",
       " 'boost',\n",
       " '.',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'air',\n",
       " '.',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'in',\n",
       " 'q',\n",
       " '##uad',\n",
       " '##rant',\n",
       " '4',\n",
       " '.',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'about',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'right',\n",
       " 'and',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'travelling',\n",
       " 'forwards',\n",
       " '.',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'travelling',\n",
       " '140',\n",
       " '##7',\n",
       " 'miles',\n",
       " 'per',\n",
       " 'hour',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "\n",
    "\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_and_align_labels(examples):\n",
    "#     tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "#     labels = []\n",
    "#     for i, label in enumerate(examples[f\"ner_ids\"]):\n",
    "#         word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "#         previous_word_idx = None\n",
    "#         label_ids = []\n",
    "#         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "#             if word_idx is None:\n",
    "#                 label_ids.append(-100)\n",
    "#             elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "#                 label_ids.append(label[word_idx])\n",
    "#             else:\n",
    "#                 label_ids.append(-100)\n",
    "#             previous_word_idx = word_idx\n",
    "#         labels.append(label_ids)\n",
    "\n",
    "#     tokenized_inputs[\"labels\"] = labels\n",
    "#     return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm heading east . I currenly have 34  percent boost . I'm not     in the air     . I'm in quadrant 4    . I'm about to turn right  and I'm travelling forwards  . I'm travelling 1407   miles per hour . \n",
      "O   LD      VDIR O O LB       O    VBA O       LB    O O   LGROUND O  O   LGROUND O O   O  LPOS     LPOS O O   O     O  LSTE VSTEER O   O   LTHROT     VTHROTTLE O O   O          VSPEED LSP   LSP LSP  O \n"
     ]
    }
   ],
   "source": [
    "words = dataset[\"train\"][0][\"tokens\"]\n",
    "labels = dataset[\"train\"][0][\"ner_ids\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_list[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # # If the label is B-XXX we change it to I-XXX\n",
    "            # if label % 2 == 1:\n",
    "            #     label += 1\n",
    "            # new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_ids\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  5312,\n",
       "  1746,\n",
       "  119,\n",
       "  146,\n",
       "  16408,\n",
       "  11604,\n",
       "  1179,\n",
       "  1193,\n",
       "  1138,\n",
       "  3236,\n",
       "  3029,\n",
       "  14112,\n",
       "  119,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  1136,\n",
       "  1107,\n",
       "  1103,\n",
       "  1586,\n",
       "  119,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  1107,\n",
       "  186,\n",
       "  18413,\n",
       "  6922,\n",
       "  125,\n",
       "  119,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  1164,\n",
       "  1106,\n",
       "  1885,\n",
       "  1268,\n",
       "  1105,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  9169,\n",
       "  22453,\n",
       "  119,\n",
       "  146,\n",
       "  112,\n",
       "  182,\n",
       "  9169,\n",
       "  8183,\n",
       "  1559,\n",
       "  1829,\n",
       "  1679,\n",
       "  2396,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  16,\n",
       "  16,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  14,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  -100]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_list[i] for i in example[f\"ner_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'LD',\n",
       " 'VDIR',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LB',\n",
       " 'O',\n",
       " 'VBA',\n",
       " 'O',\n",
       " 'LB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LGROUND',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LGROUND',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LPOS',\n",
       " 'LPOS',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LSTE',\n",
       " 'VSTEER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LTHROT',\n",
       " 'VTHROTTLE',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VSPEED',\n",
       " 'LSP',\n",
       " 'LSP',\n",
       " 'LSP',\n",
       " 'O']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    8,  ..., -100, -100, -100],\n",
       "        [-100,    0,    0,  ..., -100, -100, -100],\n",
       "        [-100,    0,   11,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100,    0,    0,  ..., -100, -100, -100],\n",
       "        [-100,    0,    8,  ..., -100, -100, -100],\n",
       "        [-100,    0,    4,  ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(50)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VDIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VBA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LGROUND seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LPOS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LSTE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VSTEER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LTHROT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VTHROTTLE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VSPEED seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LSP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(2)},\n",
       " 'BA': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'D': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'DIR': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.0),\n",
       "  'f1': np.float64(0.0),\n",
       "  'number': np.int64(1)},\n",
       " 'GROUND': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(2)},\n",
       " 'POS': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'SP': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'SPEED': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'STE': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'STEER': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'THROT': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'THROTTLE': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'overall_precision': np.float64(1.0),\n",
       " 'overall_recall': np.float64(0.9285714285714286),\n",
       " 'overall_f1': np.float64(0.962962962962963),\n",
       " 'overall_accuracy': 0.9743589743589743}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels], zero_division=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p):\n",
    "    metric = load(\"seqeval\")\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0.5)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"], \n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=17, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drone-lab68/christian/language-module/.env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"nl-ner\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50\n",
    "    # load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 36/170 01:16 < 05:02, 0.44 it/s, Epoch 0.21/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
